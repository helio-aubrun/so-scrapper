# SO Scraper

**SO Scraper** est un outil Python permettant de collecter et dâ€™analyser automatiquement les questions rÃ©centes de Stack Overflow. Il propose deux modesÂ :

- **SÃ©quentiel** (`scrape_stackoverflow`)Â : collecte page par page avec une pause configurable.
- **ParallÃ¨le** (`scrape_stackoverflow_threaded`)Â : utilise un pool de threads (`ThreadPoolExecutor`) pour accÃ©lÃ©rer les requÃªtes.

---

## ğŸ“¦ Installation

1. **Cloner le dÃ©pÃ´t**Â :
   ```bash
   git clone https://github.com/<votre-utilisateur>/so-scrapper.git
   cd so-scrapper
   ```

2. **CrÃ©er et activer lâ€™environnement**Â :
   ```bash
   # Avec venv
   python -m venv venv
   source venv/bin/activate     # macOS/Linux
   venv\Scripts\activate      # Windows

   # Ou avec Conda
   conda create -n SoScraper python=3.8
   conda activate SoScraper
   ```

3. **Installer les dÃ©pendances**Â :
   ```bash
   pip install -r requirements.txt
   ```

---

## âš™ï¸ Configuration

- **MongoDB**Â : lancer le service localement (`mongod`).
- **Variables dâ€™environnement**Â : aucune clÃ© API requise pour la version actuelle.

---

## ğŸš€ Utilisation

Le point dâ€™entrÃ©e est le fichier `scraper.py`.

### 1. Version sÃ©quentielle

```bash
python scraper.py --mode sequential --pages 5 --delay 1
```

- `--mode sequential`Â : exÃ©cute `scrape_stackoverflow`
- `--pages N`Â : nombre de pages Ã  scraper (par dÃ©fautÂ : 1)
- `--delay S`Â : pause en secondes entre chaque page (par dÃ©fautÂ : 1)

### 2. Version parallÃ¨le

```bash
python scraper.py --mode threaded --pages 10 --workers 5 --delay 0.5
```

- `--mode threaded`Â : exÃ©cute `scrape_stackoverflow_threaded`
- `--workers W`Â : nombre de threads simultanÃ©s (par dÃ©fautÂ : 5)
- `--delay S`Â : pause aprÃ¨s chaque parsing de page (par dÃ©fautÂ : 1)

> **Exemple**Â : scrap de 10 pages avec 5 threads et 0.5s de pauseÂ :
> ```bash
> python scraper.py --mode threaded --pages 10 --workers 5 --delay 0.5
> ```

---

## ğŸ“‚ Structure du projet

```text
so-scrapper/
â”œâ”€ scraper.py             # code principal (sÃ©quentiel et threaded)
â”œâ”€ bdd.py                 # insertion dans MongoDB
â”œâ”€ analyse_so_scraper.ipynb # notebook dâ€™analyse des donnÃ©es
â”œâ”€ requirements.txt       # dÃ©pendances Python
â”œâ”€ tests/                 # tests unitaires pytest
â”‚  â”œâ”€ test_scraper.py
â”‚  â””â”€ test_bdd.py
â””â”€ README.md              # documentation (ce fichier)
```

---

## ğŸ§ª Tests unitaires

Lancer tous les testsÂ :
```bash
pytest --maxfail=1 --disable-warnings -q
```

---

## ğŸ“Š Analyse des donnÃ©es

Le notebook `analyse_so_scraper.ipynb` contient :
- Connexion Ã  MongoDB
- Analyse des **tags** (Top 15)
- Analyse **NLP** des rÃ©sumÃ©s (Top mots-clÃ©s)

---

## ğŸ“œ Licence & CrÃ©dits

MIT License. DÃ©veloppÃ© par Ayoub Abderrahmane pour le projet SO Scraper.
